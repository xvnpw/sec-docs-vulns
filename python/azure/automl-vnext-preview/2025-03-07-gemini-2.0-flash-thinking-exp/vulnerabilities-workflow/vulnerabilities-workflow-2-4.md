### 1. Insecure Direct Object Reference in RAI Insights Download

- **Description:**
    - An attacker with valid Azure credentials for an Azure Machine Learning workspace might be able to download Responsible AI (RAI) insights dashboards associated with other users' AutoML runs within the same workspace, without proper authorization.
    - Step-by-step trigger:
        1. An attacker obtains valid Azure credentials that allow them to interact with an Azure Machine Learning workspace using the Azure ML SDK or CLI. This could be through compromised credentials or legitimate access to a workspace.
        2. The attacker identifies or guesses a valid `rai_insight_id` (Run ID of a 'gather' type RAI insights run) that belongs to another user's AutoML experiment in the same workspace. Run IDs might be somewhat predictable or discoverable through workspace activity logs or naming conventions if not properly secured.
        3. The attacker uses the `azure_ml_rai` Python package, specifically the `download_rai_insights` or `download_rai_insights_ux` functions, providing the targeted `rai_insight_id` and a local path to save the downloaded dashboard.
        4. The `download_rai_insights` function, using the attacker's Azure credentials, attempts to download the RAI insights artifacts from Azure Blob Storage associated with the provided `rai_insight_id`.
        5. If Azure Machine Learning's access control does not properly restrict download access to RAI insights artifacts based on user-specific permissions at the run level (and only relies on workspace-level access), the attacker will successfully download the RAI insights dashboard, even if they are not authorized to access the original AutoML run or its results.

- **Impact:**
    - Unauthorized access to sensitive information contained within RAI insights dashboards. These dashboards can include model explanations, error analysis, causal analysis, and counterfactual analysis, potentially revealing business-sensitive data, model vulnerabilities, or insights into the data used for model training.
    - Depending on the nature of the data and insights exposed, this could lead to privacy violations, competitive disadvantage, or further exploitation of identified vulnerabilities in the machine learning models or processes.

- **Vulnerability Rank:** High

- **Currently Implemented Mitigations:**
    - None evident in the provided project files. The vulnerability relies on the underlying Azure Machine Learning and MLflow authorization mechanisms. The provided code itself does not implement any explicit access control checks before downloading artifacts based on `rai_insight_id`.

- **Missing Mitigations:**
    - **Run-level Access Control Enforcement:** Azure Machine Learning should enforce granular access control at the Run level. When a user attempts to download artifacts associated with a specific Run ID (like `rai_insight_id`), the system should verify if the user has explicit permissions to access that particular Run and its outputs, beyond just having workspace-level access.
    - **Input Validation and Sanitization:** While not directly mitigating the authorization issue, input validation on `rai_insight_id` could reduce the attack surface by preventing attempts to use clearly invalid or malformed Run IDs. However, this is not a strong security measure and should not be relied upon as the primary mitigation.
    - **Auditing and Logging:** Implement detailed logging of RAI insights download attempts, including the user, the `rai_insight_id` requested, and the outcome (success or failure). This would aid in detecting and investigating potential unauthorized access attempts.

- **Preconditions:**
    - Attacker possesses valid Azure credentials with access to an Azure Machine Learning workspace.
    - The target Azure Machine Learning workspace contains RAI insights dashboards generated by other users.
    - The attacker is able to identify or guess valid `rai_insight_id` values of 'gather' type RAI insights runs from other users within the same workspace.

- **Source Code Analysis:**
    - File: `/code/src/azure-ml-rai/azure_ml_rai/_download_rai_insights.py`
    ```python
    def download_rai_insights(ml_client: MLClient, rai_insight_id: str, path: str) -> None:
        v1_ws = _get_v1_workspace_client(ml_client)

        mlflow.set_tracking_uri(v1_ws.get_mlflow_tracking_uri())

        mlflow_client = MlflowClient()

        output_directory = Path(path)
        output_directory.mkdir(parents=True, exist_ok=False)

        _download_port_files(
            mlflow_client,
            rai_insight_id,
            OutputPortNames.RAI_INSIGHTS_GATHER_RAIINSIGHTS_PORT,
            output_directory,
            ml_client._credential,
        )
    ```
    - The `download_rai_insights` function directly uses the provided `rai_insight_id` to initiate the download process via `_download_port_files`.
    - File: `/code/src/azure-ml-rai/azure_ml_rai/_download_rai_insights.py`
    ```python
    def _download_port_files(
        mlflow_client: MlflowClient,
        run_id: str, # This is rai_insight_id passed from download_rai_insights
        port_name: str,
        target_directory: Path,
        credential: ChainedTokenCredential, # User's Azure credential
    ) -> None:
        port_info = _get_output_port_info(mlflow_client, run_id, port_name) # Using run_id to get port info
        # ... (rest of the function to download using AzureBlobArtifactRepository and credential) ...
    ```
    - The `_download_port_files` function takes `run_id` (which is `rai_insight_id`) and `credential` as input. It retrieves port information using `mlflow_client.download_artifacts(run_id, port_name, temp_dir)` and then uses `AzureBlobArtifactRepository` with the provided `credential` to download artifacts.
    - **Vulnerability Point:** There is no explicit check within these functions to validate if the user associated with `ml_client._credential` is authorized to access the RAI insights dashboard corresponding to the `rai_insight_id`. The functions rely on the underlying authorization mechanisms of MLflow and Azure Blob Storage, which might only enforce workspace-level access instead of run-level access control for downloads.

- **Security Test Case:**
    1. **Setup:**
        - User A and User B both have access to the same Azure ML workspace.
        - User A creates and runs an AutoML pipeline that generates RAI insights. Let's say the 'gather' run ID for User A's RAI insights is `user_a_rai_insight_id`.
        - User B only has workspace-level access and is not explicitly granted access to User A's runs.
    2. **Action:**
        - User B, using their own Azure credentials and the `azure_ml_rai` package, executes the following Python code, replacing `<user_a_rai_insight_id>` with the actual Run ID obtained from User A's run and `<local_download_path>` with a local directory path:
        ```python
        from azure.identity import DefaultAzureCredential
        from azure.ml import MLClient
        from azure_ml_rai import download_rai_insights

        credential = DefaultAzureCredential()
        ml_client_b = MLClient(
            credential=credential,
            subscription_id="<your_subscription_id>", # User B's subscription if different, or same as User A's workspace subscription
            resource_group_name="<workspace_resource_group>",
            workspace_name="<workspace_name>",
        )

        rai_insight_id_to_download = "<user_a_rai_insight_id>" # Run ID of User A's RAI insights run
        download_path = "<local_download_path>"

        download_rai_insights(ml_client=ml_client_b, rai_insight_id=rai_insight_id_to_download, path=download_path)

        print(f"RAI Insights downloaded to: {download_path}")
        ```
    3. **Expected Result:**
        - **Vulnerable Case:** If the system is vulnerable, User B will successfully download the RAI insights dashboard from User A's run to the `<local_download_path>`, even though User B is not explicitly authorized to access User A's run.
        - **Secure Case:** If the system is secure, User B's `download_rai_insights` call will fail with an authorization error, indicating that User B does not have permission to download artifacts for `rai_insight_id_to_download`.

This test case demonstrates how an attacker (User B) could potentially exploit the Insecure Direct Object Reference vulnerability to gain unauthorized access to RAI insights dashboards created by another user (User A) within the same Azure ML workspace.